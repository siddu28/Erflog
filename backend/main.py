"""
Career Flow AI - Main Application Entry Point
FastAPI Server for Agentic AI Backend with Multi-Agent Workflow
"""

import os
import uuid
import tempfile
import shutil
from pathlib import Path
from typing import Optional, List, Dict, Any
from dotenv import load_dotenv

# Load env FIRST before any other imports
load_dotenv()

from fastapi import FastAPI, HTTPException, UploadFile, File, Form, Body
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import JSONResponse, FileResponse
from pydantic import BaseModel

# --- IMPORTS FOR AGENTS & DB ---
from core.state import AgentState
from core.db import db_manager  # Database connection

# Import routers
from agents.agent_4_operative import agent4_router

# Import Agent Nodes/Functions
from agents.agent_1_perception.graph import perception_node, app as perception_agent
from agents.agent_1_perception.github_watchdog import fetch_and_analyze_github  # <--- NEW IMPORT
from agents.agent_2_market.graph import market_scan_node
from agents.agent_3_strategist.graph import search_jobs as strategist_search_jobs, process_career_strategy
from agents.agent_6_interviewer.graph import run_interview_turn

app = FastAPI(
    title="Career Flow AI API",
    description="AI-powered career automation system with Multi-Agent Workflow",
    version="2.0.0"
)

# CORS middleware
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # Configure for production
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Include routers
app.include_router(agent4_router)

# -----------------------------------------------------------------------------
# Global Session Store
# -----------------------------------------------------------------------------
SESSIONS: Dict[str, AgentState] = {}

# -----------------------------------------------------------------------------
# Pydantic Models
# -----------------------------------------------------------------------------
class AnalyzeRequest(BaseModel):
    query: Optional[str] = None
    context: Optional[dict] = None

class SearchRequest(BaseModel):
    query: str

class KitRequest(BaseModel):
    user_name: str
    job_title: str
    job_company: str

class SessionRequest(BaseModel):
    session_id: str

class MarketScanRequest(BaseModel):
    session_id: str

class StrategyRequest(BaseModel):
    query: str  # Skills/experience to search for jobs

class ApplicationRequest(BaseModel):
    session_id: str
    job_description: Optional[str] = None

class InterviewRequest(BaseModel):
    session_id: str         # Unique session identifier for conversation state
    user_message: str = ""  # Empty for first turn (start interview)
    job_context: str        # Job title/description

# --- NEW MODEL FOR GITHUB SYNC ---
class GithubSyncRequest(BaseModel):
    session_id: str
    github_url: str

# -----------------------------------------------------------------------------
# Helper Functions
# -----------------------------------------------------------------------------
def get_session(session_id: str) -> AgentState:
    """Retrieve session state or raise 404."""
    if session_id not in SESSIONS:
        raise HTTPException(status_code=404, detail=f"Session '{session_id}' not found")
    return SESSIONS[session_id]


def initialize_state() -> AgentState:
    """Create a fresh AgentState with default values."""
    return AgentState(
        resume_text=None,
        skills=[],
        user_id=None,
        context={},
        results={}
    )

# -----------------------------------------------------------------------------
# ENDPOINTS
# -----------------------------------------------------------------------------

@app.get("/")
async def root():
    return {
        "message": "Career Flow AI API Online",
        "version": "2.0.0",
        "agents_active": 6,
        "endpoints": {
            "workflow": ["/api/init", "/api/upload-resume", "/api/market-scan", "/api/generate-strategy", "/api/generate-application"],
            "interview": "/api/interview/chat",
            "legacy": ["/api/match", "/api/generate-kit"],
            "agent4": "/agent4",
            "watchdog": "/api/sync-github" # <--- Added to documentation
        }
    }


@app.get("/health")
async def health():
    """Health check endpoint"""
    return JSONResponse(
        status_code=200,
        content={
            "status": "healthy",
            "message": "Career Flow AI Backend is running",
            "active_sessions": len(SESSIONS)
        }
    )


@app.post("/analyze")
async def analyze_career(request: AnalyzeRequest):
    """Legacy analyze endpoint"""
    return JSONResponse(
        status_code=200,
        content={
            "status": "success",
            "message": "Analysis request received",
            "data": {}
        }
    )


@app.post("/api/match")
async def match_agent(request: SearchRequest):
    """Match agent endpoint - uses Agent 3 Strategist."""
    if not request.query:
        raise HTTPException(status_code=400, detail="Query text is required")
    
    try:
        result = process_career_strategy(request.query)
        return {
            "status": "success",
            "count": result.get("matches_found", 0),
            "matches": result.get("strategy_report", [])
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Match agent error: {str(e)}")


@app.post("/api/generate-kit")
async def generate_kit_endpoint(request: KitRequest):
    """Generate deployment kit endpoint."""
    try:
        from agents.agent_4_operative import agent4_service
        result = agent4_service.generate_resume(
            user_profile={"name": request.user_name},
            job_description=f"Position: {request.job_title} at {request.job_company}"
        )
        if result.get("pdf_path"):
            return FileResponse(
                path=result["pdf_path"],
                filename=os.path.basename(result["pdf_path"]),
                media_type='application/pdf'
            )
        return JSONResponse(status_code=200, content={"status": "success", "message": "Kit generated", "data": result})
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Kit generation error: {str(e)}")


# -----------------------------------------------------------------------------
# NEW AGENT WORKFLOW ENDPOINTS
# -----------------------------------------------------------------------------

@app.post("/api/init")
async def init_session():
    session_id = str(uuid.uuid4())
    SESSIONS[session_id] = initialize_state()
    print(f"[Orchestrator] New session initialized: {session_id}")
    return {"status": "success", "session_id": session_id, "message": "Session initialized."}


@app.post("/api/upload-resume")
async def upload_resume(file: UploadFile = File(...), session_id: str = Form(...)):
    """Upload a resume PDF and run Agent 1 (Perception)."""
    state = get_session(session_id)
    
    if not file.filename.lower().endswith(".pdf"):
        raise HTTPException(status_code=400, detail="Only PDF files are accepted")
    
    try:
        temp_dir = Path(tempfile.gettempdir()) / "career_flow_uploads"
        temp_dir.mkdir(exist_ok=True)
        pdf_filename = f"{session_id}_{file.filename}"
        pdf_path = temp_dir / pdf_filename
        
        with open(pdf_path, "wb") as f:
            content = await file.read()
            f.write(content)
        
        print(f"[Orchestrator] Resume saved: {pdf_path}")
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Failed to save file: {str(e)}")
    
    state["context"]["pdf_path"] = str(pdf_path)
    
    try:
        print(f"[Orchestrator] Running Agent 1 (Perception) for session: {session_id}")
        updated_state = perception_node(state)
        SESSIONS[session_id].update(updated_state)
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Perception Agent failed: {str(e)}")
    
    perception_results = SESSIONS[session_id].get("results", {}).get("perception", {})
    return {
        "status": "success",
        "session_id": session_id,
        "profile": {
            "name": perception_results.get("name"),
            "email": perception_results.get("email"),
            "skills": SESSIONS[session_id].get("skills", []),
            "experience_summary": perception_results.get("experience_summary"),
            "education": perception_results.get("education"),
            "user_id": SESSIONS[session_id].get("user_id")
        }
    }

@app.post("/api/sync-github")
async def sync_github(request: GithubSyncRequest):
    """
    1. Analyzes the GitHub Repo using Agent 1's Watchdog.
    2. Updates the User Profile in Supabase/Session.
    3. CRITICAL: Puts NEW skills at the FRONT of the list so Agent 3 prioritizes them.
    """
    print(f"üöÄ Syncing GitHub for session: {request.session_id}")
    
    # 1. Run the Watchdog
    analysis = fetch_and_analyze_github(request.github_url)
    
    if not analysis:
        print("‚ö†Ô∏è GitHub analysis failed or returned empty.")
        return {"status": "failed", "message": "Could not analyze repo", "analysis": {}}

    new_skills = [item['skill'] for item in analysis.get('detected_skills', [])]
    print(f"‚úÖ Watchdog found new skills: {new_skills}")

    # 2. Smart Merge: New Skills First!
    # We want the search query to look like: "Pandas, Scikit-Learn, Python, ... Spring, Java"
    # This forces the AI to see the Data Science context first.
    
    current_skills = []
    if request.session_id in SESSIONS:
        current_skills = SESSIONS[request.session_id].get("skills", [])
    
    # Filter out duplicates from OLD list, keep NEW list order intact
    old_unique_skills = [s for s in current_skills if s not in new_skills]
    
    # COMBINE: NEW + OLD
    final_skills = new_skills + old_unique_skills
    
    # Update Session
    if request.session_id in SESSIONS:
        SESSIONS[request.session_id]["skills"] = final_skills
        print(f"üîÑ Session skills updated: {len(current_skills)} -> {len(final_skills)} (New skills prioritized)")

    # 3. Update Database (Persistent Storage)
    client = db_manager.get_client()
    try:
        print("üîç DB: finding most recent profile to update...")
        response = client.table("profiles").select("*").order("created_at", desc=True).limit(1).execute()

        if response.data:
            profile = response.data[0]
            profile_id = profile['id']
            
            # DB Merge (Repeat logic to be safe)
            db_existing_skills = profile.get('skills', []) or []
            db_old_unique = [s for s in db_existing_skills if s not in new_skills]
            db_final_skills = new_skills + db_old_unique
            
            # Update the DB
            client.table("profiles").update({
                "skills": db_final_skills
            }).eq("id", profile_id).execute()
            
            print(f"üíæ Updated Profile {profile_id} in DB with {len(db_final_skills)} total skills.")
            
            return {
                "status": "success", 
                "analysis": analysis,
                "updated_skills": db_final_skills # Returning ordered list
            }
        else:
             print("‚ö†Ô∏è No profile found in DB.")

    except Exception as e:
        print(f"‚ùå DB Update Error (Non-fatal): {e}")
        # Return success with the session-based skills
        return {"status": "partial_success", "analysis": analysis, "updated_skills": final_skills}

    return {"status": "success", "analysis": analysis, "updated_skills": final_skills}

# Add this model near the top with others
class WatchdogCheckRequest(BaseModel):
    session_id: str
    last_known_sha: Optional[str] = None # To avoid re-analyzing the same commit

# --- NEW ENDPOINT FOR LIVE LISTENING ---
@app.post("/api/watchdog/check")
async def watchdog_check(request: WatchdogCheckRequest):
    """
    Polls GitHub to see if the user pushed anything new.
    If NEW activity is found:
       1. Runs Analysis
       2. Updates Profile
       3. Returns new skills
    If NO change:
       Returns status="no_change"
    """
    from agents.agent_1_perception.github_watchdog import get_latest_user_activity, fetch_and_analyze_github
    
    # 1. Check what the user is doing right now
    activity = get_latest_user_activity("dummy") # Token handles auth, arg is placeholder
    
    if not activity:
        return {"status": "error", "message": "Could not fetch GitHub activity"}
        
    current_sha = activity['latest_commit_sha']
    repo_name = activity['repo_name']
    
    # 2. Compare with what the Frontend already knows
    if request.last_known_sha == current_sha:
        # User hasn't pushed anything new. Do nothing.
        return {"status": "no_change", "repo_name": repo_name}
        
    print(f"üîî LIVE WATCHDOG: New activity detected in {repo_name} (SHA: {current_sha[:7]})")
    
    # 3. New changes detected! Run the full analysis on THIS specific repo.
    analysis = fetch_and_analyze_github(activity['repo_url'])
    
    if not analysis:
        return {"status": "no_change", "message": "Analysis empty"}

    new_skills = [item['skill'] for item in analysis.get('detected_skills', [])]
    
    # 4. Update Database & Session (Reuse logic)
    # ... (Same logic as sync_github) ...
    client = db_manager.get_client()
    final_skills = new_skills
    
    try:
        # Get existing skills to merge
        if request.session_id in SESSIONS:
            existing = SESSIONS[request.session_id].get("skills", [])
            unique_old = [s for s in existing if s not in new_skills]
            final_skills = new_skills + unique_old # New first!
            SESSIONS[request.session_id]["skills"] = final_skills
            
        # Update DB
        response = client.table("profiles").select("*").order("created_at", desc=True).limit(1).execute()
        if response.data:
            profile_id = response.data[0]['id']
            client.table("profiles").update({"skills": final_skills}).eq("id", profile_id).execute()
            
    except Exception as e:
        print(f"‚ùå DB Error: {e}")

    return {
        "status": "updated",
        "repo_name": repo_name,
        "new_sha": current_sha,
        "updated_skills": final_skills,
        "analysis": analysis
    }


@app.post("/api/market-scan")
async def market_scan(request: MarketScanRequest):
    """Run Agent 2 (Market Sentinel) to find job matches."""
    session_id = request.session_id
    state = get_session(session_id)
    try:
        print(f"[Orchestrator] Running Agent 2 (Market) for session: {session_id}")
        updated_state = market_scan_node(state)
        SESSIONS[session_id].update(updated_state)
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Market Agent failed: {str(e)}")
    market_results = SESSIONS[session_id].get("results", {}).get("market", {})
    job_matches = market_results.get("job_matches", [])
    return {"status": "success", "session_id": session_id, "job_matches": job_matches, "total_matches": len(job_matches)}


@app.post("/api/generate-strategy")
async def generate_strategy(request: StrategyRequest):
    """Run Agent 3 (Strategist) for semantic job matching with roadmaps."""
    query_text = request.query.strip()
    if not query_text:
        raise HTTPException(status_code=400, detail="Query is required for job matching.")
    try:
        print(f"[Orchestrator] Running Agent 3 (Strategist) with query: {query_text[:100]}...")
        result = process_career_strategy(query_text)
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Strategist Agent failed: {str(e)}")
    
    return {
        "status": "success",
        "strategy": {
            "matched_jobs": result.get("strategy_report", []),
            "total_matches": result.get("matches_found", 0),
            "query_used": query_text[:200],
            "tier_summary": {
                "A_ready": len([j for j in result.get("strategy_report", []) if j.get("tier") == "A"]),
                "B_roadmap": len([j for j in result.get("strategy_report", []) if j.get("tier") == "B"]),
                "C_low": len([j for j in result.get("strategy_report", []) if j.get("tier") == "C"])
            }
        }
    }


@app.post("/api/generate-application")
async def generate_application(request: ApplicationRequest):
    """Run Agent 4 (Operative) to generate tailored resume and outreach."""
    session_id = request.session_id
    state = get_session(session_id)
    job_description = request.job_description
    if not job_description:
        strategist_results = state.get("results", {}).get("strategist", {})
        matched_jobs = strategist_results.get("matched_jobs", [])
        if matched_jobs: job_description = matched_jobs[0].get("description", "")
    if not job_description:
        market_results = state.get("results", {}).get("market", {})
        job_matches = market_results.get("job_matches", [])
        if job_matches: job_description = job_matches[0].get("description", job_matches[0].get("summary", ""))
    if not job_description:
        raise HTTPException(status_code=400, detail="job_description is required")
    
    perception_results = state.get("results", {}).get("perception", {})
    user_profile = {
        "name": perception_results.get("name"),
        "email": perception_results.get("email"),
        "skills": state.get("skills", []),
        "experience_summary": perception_results.get("experience_summary"),
        "education": perception_results.get("education"),
        "resume": perception_results.get("resume_json", {})
    }
    
    try:
        print(f"[Orchestrator] Running Agent 4 (Operative) for session: {session_id}")
        from agents.agent_4_operative.graph import run_agent4
        operative_result = run_agent4(job_description, user_profile)
        if "results" not in SESSIONS[session_id]: SESSIONS[session_id]["results"] = {}
        SESSIONS[session_id]["results"]["operative"] = operative_result
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Operative Agent failed: {str(e)}")
    
    return {
        "status": "success",
        "session_id": session_id,
        "application": {
            "pdf_path": operative_result.get("pdf_path"),
            "pdf_url": operative_result.get("pdf_url"),
            "recruiter_email": operative_result.get("recruiter_email"),
            "application_status": operative_result.get("application_status"),
            "rewritten_content": operative_result.get("rewritten_content")
        }
    }


@app.post("/api/interview/chat")
async def interview_chat(request: InterviewRequest):
    """Agent 6: Interview Chat Endpoint"""
    if not request.session_id: raise HTTPException(status_code=400, detail="session_id is required")
    if not request.job_context: raise HTTPException(status_code=400, detail="job_context is required")
    try:
        result = run_interview_turn(session_id=request.session_id, user_message=request.user_message, job_context=request.job_context)
        return {"status": "success", "response": result["response"], "stage": result["stage"], "message_count": result["message_count"]}
    except Exception as e:
        print(f"‚ùå Interview Error: {e}")
        raise HTTPException(status_code=500, detail=f"Interview agent error: {str(e)}")

# -----------------------------------------------------------------------------
# Entry Point
# -----------------------------------------------------------------------------
if __name__ == "__main__":
    import uvicorn
    port = int(os.getenv("PORT", 8000))
    uvicorn.run(app, host="0.0.0.0", port=port, log_level="info")